# CANDELA – Project Brief (v0.1.1 - May 2025)

**CANDELA: Compliant Auditable Natural-language Directive Enforcement & Ledger Anchoring**

## Elevator Pitch

**CANDELA adds a blockchain-anchored "Directive Guardian" layer in front of any Large Language Model (LLM). It transforms often fragile LLM prompt rules and behavioral guidelines into a verifiable and auditable governance system.**

---

## The Problem: Unreliable & Opaque AI

Current Large Language Models (LLMs), while incredibly powerful, often exhibit unpredictable behavior. They can produce incorrect information ("hallucinate"), deviate from instructions ("drift"), and their internal decision-making processes are largely opaque ("black boxes"). This lack of inherent reliability and transparency poses significant risks, limiting their trustworthiness for critical applications and making true accountability difficult to achieve.

## CANDELA's Solution: Verifiable Pre-Execution Governance

CANDELA introduces the **"Directive Guardian,"** a middleware software component designed to sit between a user (or application) and an LLM. The Guardian enforces a predefined, human-readable set of behavioral and cognitive rules called the **"Directive Scaffold."**

The core principles are:

1.  **Defined Rule-Set:** The Directive Scaffold (currently 76 directives, including examples of "micro-directives" for complex concepts) is stored in a machine-readable JSON format (`src/directives_schema.json`).
2.  **Integrity via Blockchain Anchoring:** Before the Guardian uses these directives, it calculates a unique cryptographic fingerprint (SHA-256 hash) of the entire directive set. This hash is then recorded ("anchored") on a public blockchain testnet (e.g., Polygon Mumbai or Ethereum Sepolia). This creates an immutable, publicly verifiable record of the exact rule-set that *should* be in force.
3.  **Runtime Verification:** At the start of an interaction, the Guardian verifies the integrity of its local directive set by comparing its hash against the canonical hash retrieved from the blockchain.
4.  **Guided LLM Output:** The Guardian strategically incorporates the verified directives into prompts sent to the LLM.
5.  **Automated Validation:** The Guardian checks the LLM's responses against the requirements of the active directives (especially "auto" tier micro-directives in the current PoC).
6.  **Accountability Loop:** The system enables an auditable trail from the enforced rules to the LLM's behavior, with options to also anchor hashes of interactions.

---

## Key Innovations & Benefits

* **Pre-Execution Rule Verification:** Ensures the governing rule-set's integrity *before* the LLM generates output.
* **Micro-Directives:** Decomposes complex abstract concepts (like "First-Principles Reasoning") into smaller, concrete, and more easily testable steps for the LLM and Guardian.
* **Transparency & Auditability:** Human-readable directives coupled with blockchain-anchored verification provide unprecedented oversight.
* **Enhanced LLM Reliability:** Aims to reduce hallucinations, instructional drift, and inconsistencies.
* **Open & Model-Agnostic Potential:** Designed as an open-source (MIT licensed) middleware layer.
* **Addressing "AI Slop" & Supporting Content Creators (Future Vision):** The framework's principles could be extended to verify human-generated content against defined standards, potentially combating low-quality "AI slop" and enabling fairer monetization for original creators.

---

## Current Status (v0.1 Proof-of-Concept - May 16, 2025)

* **Core PoC Established:**
    * The `src/guardian_poc_v0.1.py` script successfully demonstrates loading the `src/directives_schema.json` (v3.2, 76 directives), computing its SHA-256 hash, and simulating the core Guardian workflow with mock LLM calls and blockchain anchoring.
    * **Successful Directive Bundle Hash Generation:**
        * **Hash:** `7b8d69ce1ca0a4c03e764b7c8f4f2dc64416dfc6a0081876ce5ff9f53a90c73d`
        * *(This hash for `directives_schema.json` v3.2 was generated by `src/guardian_poc_v0.1.py` on 2025-05-12 and documented in `First successful file hash.txt` and the main `README.md`)*.
    * **Symbolic Manual Anchoring:** The above hash has been manually anchored on a public testnet as a v0.1 PoC step (details in `README.md`).
* **Documentation Suite:** A comprehensive set of documents including `README.md`, this `PROJECT_BRIEF.md`, `FAQ.md`, `TECH_SPEC.md`, `ROADMAP.md`, and `directives_README.md` are available in the [CANDELA GitHub Repository](https://github.com/jebus197/CANDELA). * **OSF Preregistration & DOI:** Core documents are being registered on the Open Science Framework for a persistent citable DOI. ---

## Key Components (v0.1 PoC)

1.  **Directive Guardian (Software Concept):** Implemented as `src/guardian_poc_v0.1.py` (illustrative Python middleware).
2.  **Directive Schema (`src/directives_schema.json`):** The v3.2 machine-readable rule list.
3.  **Validation Tiers (Concept):** Directives are conceptually tiered ("auto," "semi," "human") for phased implementation of validation logic (detailed in `directives_README.md`). Current PoC focuses on illustrating the mechanism for "auto" tier checks.
4.  **Blockchain Anchoring (PoC):** Mocked in script, with manual symbolic anchoring of the directive hash completed. Automated testnet anchoring is a v0.2/v0.3 goal.

---

## Roadmap Snapshot (See [ROADMAP.md](ROADMAP.md) for full details)

| Version                   | Key Milestone                                                                                             | Target      |
| :------------------------ | :-------------------------------------------------------------------------------------------------------- | :---------- |
| **v0.2 (June-July 2025)** | Implement real LLM API calls. Guardian performs automated Testnet anchoring & verification of directive hash. Basic "auto" tier validation logic for select micro-directives. | Planned     |
| **v0.3 (July-Aug 2025)** | Enhanced validation suite. Explore semantic linking of directives (PoC). Initial unit testing framework.        | Planned     |
| **v0.4+ (Q4 2025 Onwards)** | Guardian flags low-confidence outputs. "Must-Cite" rule features. Public Beta. Academic Case Study.         | Planned     |

---

## How to Get Started & Contribute

1.  **Clone the Repository:**
    ```bash
    git clone [https://github.com/jebus197/CANDELA.git](https://github.com/jebus197/CANDELA.git) 
    # Replace with your actual repo link
    cd CANDELA
    ```
2.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Run the Proof-of-Concept:**
    ```bash
    python3 src/guardian_poc_v0.1.py
    ```
    This will demonstrate the directive loading, hashing, and mock interaction flow.

We welcome contributions! See our `TECH_SPEC.md` for developer to-dos, `ROADMAP.md` for future plans, and the [Issues Tab](https://github.com/jebus197/CANDELA/issues) on GitHub. ---

*CANDELA – Illuminating AI governance through verifiable directives.*
*Copyright (c) 2024-2025 George Jackson (CANDELA Project Lead). MIT Licensed.*